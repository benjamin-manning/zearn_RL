teacher-1)+week
40*(teacher-1)+week
#how do we get badges???
state_var_df[40*(teacher-1)+week,] = c(week, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
View(state_var_df)
mu_theta_df[40*(teacher-1)+week,2]
mu_theta_df
40*(teacher-1)
mu = as.numeric(mu_theta_df[40*(teacher-1)+week-1,2]*state_var_df[40*(teacher-1)+week-1,2]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5])
u
mu
mu_theta_df[40*(teacher-1)+week-1,2]
state_var_df[40*(teacher-1)+week-1,2])
state_var_df[40*(teacher-1)+week-1,2])
mu = as.numeric(mu_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6])
mu
#final sim sigma (linear combination)
sigma = exp(as.numeric(sig_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6]))
sigma
minutes = rnorm(1, mean = mu, sd = sigma)
minutes = ifelse(minutes < 0, 0, minutes)
minutes
minutes
minutes
minutes
minutes
#simualted minutes per wee
sim_mins_df[teacher,week] = minutes
View(sim_mins_df)
40*(teacher-1)+week-1
40*(teacher-1)+week-1
40*(teacher-1)+week-1
40*(teacher-1)+week-1
40*(teacher-1)+week-1
40*(teacher-1)+week-1
40*(teacher-1)+week
delta = last_badges +
gamma * state_var_df[40*(teacher-1)+week,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)] -
state_var_df[40*(teacher-1)+week-1,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)]
delta
delta = delta[[1]]
w_df
w_df[1,]
state_var_df[40*(teacher-1)+week,]
state_var_df[40*(teacher-1)+week,c(1:2)]
View(state_var_df)
View(state_var_df)
nweeks <- 40
nteachers = 100
# 1. Initialize: alpha_theta >0, alpha_w > 0; theta_mu, theta_sigma, w (vectors size 4);
# S (x) (which is the vector size 4 we call x’s — badges, tower alerts, squares…)
alpha_theta = .1
alpha_w = .1
gamma = .95
#thetas hyper
mu_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(mu_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
sig_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(sig_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
#state_variables_df THIS IS X
state_var_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(state_var_df) = c('week', 'teacher','x1', 'x2', 'x3', 'x4')
#w starting
w_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(w_df) = c('week', 'teacher', 'w1', 'w2', 'w3', 'w4')
#FIX HERE
sim_mins_df = matrix(data = NA, nrow = nteachers , ncol = 40)
# 2. Calculate mu and theta. Sample minutes from the resulting normal distribution.
#iteratin
teacher = 1
#selecting thetas MAKE ALL THESE 0 to START
mu_theta_df[40* (teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
sig_theta_df[40*(teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
#starting state variables for each teacher (the same?)
last_badges = 2
last_tower_alerts = 6
state_var_df[40*(teacher-1)+1,] = c(1, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
#initializing w for each teacher
w_df[40*(teacher-1)+1,]= c(1, teacher,0, 0, 0, 0)
#making first column teacher
sim_mins_df[teacher,1] = teacher
View(w_df)
week = 2
#hyperparameters get big with the growing weeks
#updating badges
last_badges  = rnorm(1, mean = 2, sd = .5)
last_badges = ifelse(last_badges < 0, 0, last_badges)
last_tower_alerts  = rnorm(1, mean = 6, sd = 1)
last_tower_alerts= ifelse(last_tower_alerts < 0, 0, last_tower_alerts)
#how do we get badges???
state_var_df[40*(teacher-1)+week,] = c(week, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
mu = as.numeric(mu_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6])
#final sim sigma (linear combination)
sigma = exp(as.numeric(sig_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6]))
minutes = rnorm(1, mean = mu, sd = sigma)
minutes = ifelse(minutes < 0, 0, minutes)
#simualted minutes per wee
sim_mins_df[teacher,week] = minutes
delta = last_badges +
gamma * state_var_df[40*(teacher-1)+week,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)] -
state_var_df[40*(teacher-1)+week-1,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)]
delta = delta[[1]]
state_var_df[40*(teacher-1)+week,c(1:2)]
w_df[40*(teacher-1)+week,c(1:2)]
w_df[40*(teacher-1)+week,c(1:2)]
#4. update w. Like so: w = w + alpha_w * delta * w
#[this is like the updating function we did with each state before]
w_df[40*(teacher-1)+week,c(1:2)] = c(week, teacher)
w_df[40*(teacher-1)+week,c(1:2)]
w_df[week,c(2:5)]
as.vector(w_df[week-1,c(3:6)])
as.vector(w_df[week,c(3:6)])
state_var_df[week-1,c(3:6)]
state_var_df[week-1,c(3:6)]
state_var_df[week-1,c(3:6)]
as.vector(state_var_df[week-1,c(3:6)])
as.vector(w_df[week-1,c(3:6)]) + alpha_w * delta * as.vector(state_var_df[week-1,c(3:6)])
as.vector(state_var_df[40*(teacher-1)+week-1,c(3:6)])
as.vector(w_df[40*(teacher-1)+week-1,c(3:6)])
library(tidyverse)
library(reshape2)
nweeks <- 40
nteachers = 100
# 1. Initialize: alpha_theta >0, alpha_w > 0; theta_mu, theta_sigma, w (vectors size 4);
# S (x) (which is the vector size 4 we call x’s — badges, tower alerts, squares…)
alpha_theta = .1
alpha_w = .1
gamma = .95
#thetas hyper
mu_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(mu_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
sig_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(sig_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
#state_variables_df THIS IS X
state_var_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(state_var_df) = c('week', 'teacher','x1', 'x2', 'x3', 'x4')
#w starting
w_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(w_df) = c('week', 'teacher', 'w1', 'w2', 'w3', 'w4')
#FIX HERE
sim_mins_df = matrix(data = NA, nrow = nteachers , ncol = 40)
# 2. Calculate mu and theta. Sample minutes from the resulting normal distribution.
#iterating through teachers
for (teacher in 1:nteachers){
teacher = 1
#selecting thetas MAKE ALL THESE 0 to START
mu_theta_df[40* (teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
sig_theta_df[40*(teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
#starting state variables for each teacher (the same?)
last_badges = 2
last_tower_alerts = 6
state_var_df[40*(teacher-1)+1,] = c(1, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
#initializing w for each teacher
w_df[40*(teacher-1)+1,]= c(1, teacher,0, 0, 0, 0)
#making first column teacher
sim_mins_df[teacher,1] = teacher
#iterating through weeks
for (week in 2:nweeks) {
week = 2
#hyperparameters get big with the growing weeks
#updating badges
last_badges  = rnorm(1, mean = 2, sd = .5)
last_badges = ifelse(last_badges < 0, 0, last_badges)
last_tower_alerts  = rnorm(1, mean = 6, sd = 1)
last_tower_alerts= ifelse(last_tower_alerts < 0, 0, last_tower_alerts)
#how do we get badges???
state_var_df[40*(teacher-1)+week,] = c(week, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
#final sim mu
mu = as.numeric(mu_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6])
#final sim sigma (linear combination)
sigma = exp(as.numeric(sig_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6]))
minutes = rnorm(1, mean = mu, sd = sigma)
minutes = ifelse(minutes < 0, 0, minutes)
#simualted minutes per wee
sim_mins_df[teacher,week] = minutes
#3. calculate delta = badges for the NEXT week + gamma *
#(linear combination of w with x’s for the NEXT week) -
#(linear combination of w with x’s for the THIS week)
#(oh and gamma = 0.95)
delta = last_badges +
gamma * state_var_df[40*(teacher-1)+week,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)] -
state_var_df[40*(teacher-1)+week-1,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)]
delta = delta[[1]]
#4. update w. Like so: w = w + alpha_w * delta * X
#[this is like the updating function we did with each state before]
w_df[40*(teacher-1)+week,c(1:2)] = c(week, teacher)
w_df[40*(teacher-1)+week,c(3:6)] = as.vector(w_df[40*(teacher-1)+week-1,c(3:6)]) + alpha_w * delta * as.vector(state_var_df[40*(teacher-1)+week-1,c(3:6)])
#5. update theta_mu. Like so: theta_mu = theta_mu + alpha_theta * delta*gamma^(week -1#) *
#1/(sigma)^2 * (minutes - mu) * x’s  [this is the first gradient formula from the picture]
mu_theta_df[40*(teacher-1)+1 + (week-1),c(1:2)] = c(week, teacher)
mu_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)] = mu_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)] + alpha_theta * delta*gamma^(week-1) *
1/(sigma^2) * (minutes - mu) *state_var_df[40*(teacher-1)+1 + (week-1),c(2:5)]
#6. update theta_sigma. Like so: theta_sigma = theta_sigma + alpha_theta * delta*gamma^(week -1 #) *
#((minutes - mu)^2/(sigma)^2 - 1) * x’s  [this is the second gradient formula from the picture]
sig_theta_df[40*(teacher-1)+1 + (week-1),c(1:2)] = c(week, teacher)
sig_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)] = sig_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)] + alpha_theta * delta*gamma^(week-1) *
((minutes-mu)^2/((sigma^2-1))) *state_var_df[40*(teacher-1)+1 + (week-1),c(2:5)]
}
}
# 7. Loop accordingly until the end of the 40 weeks
View(mu_theta_df)
library(tidyverse)
library(reshape2)
nweeks <- 40
nteachers = 100
# 1. Initialize: alpha_theta >0, alpha_w > 0; theta_mu, theta_sigma, w (vectors size 4);
# S (x) (which is the vector size 4 we call x’s — badges, tower alerts, squares…)
alpha_theta = .1
alpha_w = .1
gamma = .95
#thetas hyper
mu_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(mu_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
sig_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(sig_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
#state_variables_df THIS IS X
state_var_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(state_var_df) = c('week', 'teacher','x1', 'x2', 'x3', 'x4')
#w starting
w_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(w_df) = c('week', 'teacher', 'w1', 'w2', 'w3', 'w4')
#FIX HERE
sim_mins_df = matrix(data = NA, nrow = nteachers , ncol = 40)
# 2. Calculate mu and theta. Sample minutes from the resulting normal distribution.
#iterating through teachers
for (teacher in 1:nteachers){
#teacher = 1
#selecting thetas MAKE ALL THESE 0 to START
mu_theta_df[40* (teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
sig_theta_df[40*(teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
#starting state variables for each teacher (the same?)
last_badges = 2
last_tower_alerts = 6
state_var_df[40*(teacher-1)+1,] = c(1, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
#initializing w for each teacher
w_df[40*(teacher-1)+1,]= c(1, teacher,0, 0, 0, 0)
#making first column teacher
sim_mins_df[teacher,1] = teacher
#iterating through weeks
for (week in 2:nweeks) {
#week = 2
#hyperparameters get big with the growing weeks
#updating badges
last_badges  = rnorm(1, mean = 2, sd = .5)
last_badges = ifelse(last_badges < 0, 0, last_badges)
last_tower_alerts  = rnorm(1, mean = 6, sd = 1)
last_tower_alerts= ifelse(last_tower_alerts < 0, 0, last_tower_alerts)
#how do we get badges???
state_var_df[40*(teacher-1)+week,] = c(week, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
#final sim mu
mu = as.numeric(mu_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6])
#final sim sigma (linear combination)
sigma = exp(as.numeric(sig_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6]))
minutes = rnorm(1, mean = mu, sd = sigma)
minutes = ifelse(minutes < 0, 0, minutes)
#simualted minutes per wee
sim_mins_df[teacher,week] = minutes
#3. calculate delta = badges for the NEXT week + gamma *
#(linear combination of w with x’s for the NEXT week) -
#(linear combination of w with x’s for the THIS week)
#(oh and gamma = 0.95)
delta = last_badges +
gamma * state_var_df[40*(teacher-1)+week,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)] -
state_var_df[40*(teacher-1)+week-1,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)]
delta = delta[[1]]
#4. update w. Like so: w = w + alpha_w * delta * X
#[this is like the updating function we did with each state before]
w_df[40*(teacher-1)+week,c(1:2)] = c(week, teacher)
w_df[40*(teacher-1)+week,c(3:6)] = as.vector(w_df[40*(teacher-1)+week-1,c(3:6)]) + alpha_w * delta * as.vector(state_var_df[40*(teacher-1)+week-1,c(3:6)])
# FINISHED THROUGH HERE!!!
#5. update theta_mu. Like so: theta_mu = theta_mu + alpha_theta * delta*gamma^(week -1#) *
#1/(sigma)^2 * (minutes - mu) * x’s  [this is the first gradient formula from the picture]
mu_theta_df[40*(teacher-1)+1 + (week-1),c(1:2)] = c(week, teacher)
mu_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)] = mu_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)] + alpha_theta * delta*gamma^(week-1) *
1/(sigma^2) * (minutes - mu) *state_var_df[40*(teacher-1)+1 + (week-1),c(2:5)]
#6. update theta_sigma. Like so: theta_sigma = theta_sigma + alpha_theta * delta*gamma^(week -1 #) *
#((minutes - mu)^2/(sigma)^2 - 1) * x’s  [this is the second gradient formula from the picture]
sig_theta_df[40*(teacher-1)+1 + (week-1),c(1:2)] = c(week, teacher)
sig_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)] = sig_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)] + alpha_theta * delta*gamma^(week-1) *
((minutes-mu)^2/((sigma^2-1))) *state_var_df[40*(teacher-1)+1 + (week-1),c(2:5)]
}
}
# 7. Loop accordingly until the end of the 40 weeks
View(sig_theta_df)
View(sim_mins_df)
View(sim_mins_df)
View(state_var_df)
View(w_df)
View(sim_mins_df)
nweeks <- 40
nteachers = 100
# 1. Initialize: alpha_theta >0, alpha_w > 0; theta_mu, theta_sigma, w (vectors size 4);
# S (x) (which is the vector size 4 we call x’s — badges, tower alerts, squares…)
alpha_theta = .1
alpha_w = .1
gamma = .95
#thetas hyper
mu_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(mu_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
sig_theta_df = matrix(data = NA, nrow = nteachers*nweeks, ncol = 6)
colnames(sig_theta_df) = c('week', 'teacher', 'theta1', 'theta2', 'theta3', 'theta4')
#state_variables_df THIS IS X
state_var_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(state_var_df) = c('week', 'teacher','x1', 'x2', 'x3', 'x4')
#w starting
w_df = matrix(data = NA, nrow = nteachers*nweeks , ncol = 6)
colnames(w_df) = c('week', 'teacher', 'w1', 'w2', 'w3', 'w4')
#FIX HERE
sim_mins_df = matrix(data = NA, nrow = nteachers , ncol = 40)
# 2. Calculate mu and theta. Sample minutes from the resulting normal distribution.
teacher = 1
#selecting thetas MAKE ALL THESE 0 to START
mu_theta_df[40* (teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
sig_theta_df[40*(teacher-1)+1,]  = c(1, teacher, 0, 0, 0, 0)
#starting state variables for each teacher (the same?)
last_badges = 2
last_tower_alerts = 6
state_var_df[40*(teacher-1)+1,] = c(1, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
#initializing w for each teacher
w_df[40*(teacher-1)+1,]= c(1, teacher,0, 0, 0, 0)
#making first column teacher
sim_mins_df[teacher,1] = teacher
week = 2
#hyperparameters get big with the growing weeks
#updating badges
last_badges  = rnorm(1, mean = 2, sd = .5)
last_badges = ifelse(last_badges < 0, 0, last_badges)
last_tower_alerts  = rnorm(1, mean = 6, sd = 1)
last_tower_alerts= ifelse(last_tower_alerts < 0, 0, last_tower_alerts)
#how do we get badges???
state_var_df[40*(teacher-1)+week,] = c(week, teacher, last_tower_alerts, last_badges, last_tower_alerts^2, last_badges^2)
mu = as.numeric(mu_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(mu_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6])
#final sim sigma (linear combination)
sigma = exp(as.numeric(sig_theta_df[40*(teacher-1)+week-1,3]*state_var_df[40*(teacher-1)+week-1,3]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,4]*state_var_df[40*(teacher-1)+week-1,4]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,5]*state_var_df[40*(teacher-1)+week-1,5]) +
as.numeric(sig_theta_df[40*(teacher-1)+week-1,6]*state_var_df[40*(teacher-1)+week-1,6]))
minutes = rnorm(1, mean = mu, sd = sigma)
minutes = ifelse(minutes < 0, 0, minutes)
#simualted minutes per wee
sim_mins_df[teacher,week] = minutes
delta = last_badges +
gamma * state_var_df[40*(teacher-1)+week,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)] -
state_var_df[40*(teacher-1)+week-1,c(2:5)] %*% w_df[40*(teacher-1)+week-1,c(2:5)]
delta = delta[[1]]
#4. update w. Like so: w = w + alpha_w * delta * X
#[this is like the updating function we did with each state before]
w_df[40*(teacher-1)+week,c(1:2)] = c(week, teacher)
w_df[40*(teacher-1)+week,c(3:6)] = as.vector(w_df[40*(teacher-1)+week-1,c(3:6)]) + alpha_w * delta * as.vector(state_var_df[40*(teacher-1)+week-1,c(3:6)])
#5. update theta_mu. Like so: theta_mu = theta_mu + alpha_theta * delta*gamma^(week -1#) *
#1/(sigma)^2 * (minutes - mu) * x’s  [this is the first gradient formula from the picture]
mu_theta_df[40*(teacher-1)+1 + (week-1),c(1:2)] = c(week, teacher)
View(mu_theta_df)
mu_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)]
mu_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)]
40*(teacher-1)+1 + (week-1)-1
alpha_thet
alpha_theta
delta
gamma^(week-1)
1/(sigma^2)
(minutes - mu)
40*(teacher-1)+1 + (week-1)
40*(teacher-1)+1 + (week-1)-1
40*(teacher-1)+1 + (week-1)
#5. update theta_mu. Like so: theta_mu = theta_mu + alpha_theta * delta*gamma^(week -1#) *
#1/(sigma)^2 * (minutes - mu) * x’s (IS THIS WEEK -1 ???)  [this is the first gradient formula from the picture]
mu_theta_df[40*(teacher-1)+1 + (week-1),c(1:2)] = c(week, teacher)
mu_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)] = mu_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)] + alpha_theta * delta*gamma^(week-1) *
1/(sigma^2) * (minutes - mu) *state_var_df[40*(teacher-1)+1 + (week-1),c(2:5)]
View(mu_theta_df)
#6. update theta_sigma. Like so: theta_sigma = theta_sigma + alpha_theta * delta*gamma^(week -1 #) *
#((minutes - mu)^2/(sigma)^2 - 1) * x’s  [this is the second gradient formula from the picture]
sig_theta_df[40*(teacher-1)+1 + (week-1),c(1:2)] = c(week, teacher)
sig_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)] = sig_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)] + alpha_theta * delta*gamma^(week-1) *
((minutes-mu)^2/((sigma^2-1))) *state_var_df[40*(teacher-1)+1 + (week-1),c(2:5)]
View(sig_theta_df)
sig_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)]
alpha_theta * delta*gamma^(week-1)
((minutes-mu)^2
(minutes-mu)
sig_theta_df[40*(teacher-1)+1 + (week-1),c(3:6)] = sig_theta_df[40*(teacher-1)+1 + (week-1)-1,c(3:6)] + alpha_theta * delta*gamma^(week-1) *
(IS THIS WEEK -1 ???)s>D?  }
minutes-mu
(minutes-mu)^2
((minutes-mu)^2/((sigma^2-1)))
sigma
2-1
sigma^2-1)
##### PRoblem 9
#control
mu.c <- 1.013 + (0.24/sqrt(32))*rt(1000,31)
mu.t <- 1.173 + (0.20/sqrt(36))*rt(1000,35)
par(mfcol=c(2,1))
hist(mu.c)
abline(v = mean(mu.c),col = 'red')
hist(mu.t)
abline(v = mean(mu.t),col = 'red')
dif <- mu.t - mu.c
##### PRoblem 9
#control
mu.c <- 1.013 + (0.24/sqrt(32))*rt(1000,31)
mu.t <- 1.173 + (0.20/sqrt(36))*rt(1000,35)
par(mfcol=c(2,1))
hist(mu.c)
abline(v = mean(mu.c),col = 'red')
hist(mu.t)
abline(v = mean(mu.t),col = 'red')
dif <- mu.t - mu.c
hist (dif, xlab="mu_t - mu_c", yaxt="n",
breaks=seq(-.1,.4,.02))
quantile(dif , probs = c(0.025, 0.975))
# init sim
c_mu = 1.013
c_var = (0.24^2) / 32
c_df = 31
t_mu = 1.173
t_var = (0.20^2) / 36
t_df = 35
n = 10000
# generate random samples from each of the distribs
c_samples = c_mu + ((c_var) ^ 0.5) * rt(n, c_df)
t_samples = t_mu + ((t_var) ^ 0.5) * rt(n, t_df)
# compute the sample differences
difs = t_samples - c_samples
# plot histogram of difs
hist(difs, xlab = "mu_t - mu_c")
# get the interval
interval = quantile(difs, c(.025, .975))
interval
# init
alpha_mu = 24
alpha_std = 2
beta_mu = -0.55
beta_std = 0.5
# specify a grid for alpha and beta
alpha_grid = seq(alpha_mu - 3.5 * alpha_std, alpha_mu + 3.5 * alpha_std, length = 500)
beta_grid = seq(beta_mu - 3.5 * beta_std, beta_mu + 3.5 * beta_std, length = 500)
alpha_grid
beta_grid
# get the joint probabilities
joint_prob=matrix(NA, length(alpha_grid), length(beta_grid))
for(i in seq(1,length(alpha_grid))){
for(j in seq(1,length(beta_grid))){
# get the joint probability (independent)
joint_prob[i,j] = dnorm(alpha_grid[i], alpha_mu, alpha_std) * dnorm(beta_grid[j], beta_mu, beta_std)
}
}
# let's make the contour plot
contour(alpha_grid, beta_grid, joint_prob, xlab="alpha", ylab="beta", main = "Joint probability contour plot of alpha and beta")
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
dnorm(alpha_grid[i], alpha_mu, alpha_std)
norm(beta_grid[j], beta_mu, beta_std)
dnorm(beta_grid[j], beta_mu, beta_std)
# let's make the contour plot
contour(alpha_grid, beta_grid, joint_prob, xlab="alpha", ylab="beta", main = "Joint probability contour plot of alpha and beta")
# load the data
df = read.table("/Users/benauerbach/Dropbox/STAT927/hw/hw1/planes.txt", sep = '\t', header = TRUE)
# run linear regression to get crude estimates on alpha and beta
df["year"]= df["year"] - 1976
res = lm(formula = fatal ~ year, data = df)
# load the data
df = read.table("data/planes.txt", sep = '\t', header = TRUE)
# load the data
df = read.table("data\planes.txt", sep = '\t', header = TRUE)
##### PRoblem `10`
data <- read.table("planes.txt",skip=1)
##### PRoblem `10`
data <- read.table("data/planes.txt",skip=1)
##### PRoblem `10`
data <- read.table("data\planes.txt",skip=1)
##### PRoblem `10`
data <- read.table("\data\planes.txt",skip=1)
##### PRoblem `10`
data <- read.table("data/planes.txt",skip=1)
